{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024e6931",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable autoreload for automatic module reloading\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f97589b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modification Copyright© 2025 Advanced Micro Devices, Inc. All rights reserved.\n",
    "\n",
    "import torch, os\n",
    "\n",
    "from models.ar_model import Instella_AR_Model, BinaryAR\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from PIL import Image\n",
    "from bae.ae_model import BAE_Model\n",
    "import gc\n",
    "from mmengine.config import Config\n",
    "import argparse\n",
    "from safetensors.torch import load_file as safe_load_file\n",
    "from huggingface_hub import snapshot_download\n",
    "cuda_num = 0\n",
    "torch.cuda.set_device(cuda_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2bee33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seeds for reproducible results\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def set_seeds(seed=42):\n",
    "    \"\"\"Set all random seeds for reproducibility\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # For multi-GPU setups\n",
    "    \n",
    "    # Make CuDNN deterministic (may impact performance)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "    # Set Python hash seed for complete reproducibility\n",
    "    import os\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    \n",
    "    print(f\"All seeds set to {seed} for reproducible results\")\n",
    "\n",
    "# Set the seed\n",
    "SEED = 42\n",
    "set_seeds(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13128a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from types import SimpleNamespace\n",
    "\"\"\"Create args namespace with default configuration values\"\"\"\n",
    "args = SimpleNamespace(\n",
    "    ckpt_path='./checkpoints',           # Path to the diffusion model ckpt\n",
    "    num_tkn=128,                         # Number of image tokens for the BAE tokenizer\n",
    "    image_size=1024,                      # Output image size (512, 768, or 1024)\n",
    "    codesize=128,                        # Codebook size of the BAE tokenizer\n",
    "    cfg_scale=7.5,                       # Scale of classifier-free guidance\n",
    "    temp=1.0,                           # Temperature for sampling\n",
    "    rho=1.0,                            # Rho for sampling\n",
    "    num_steps=50,                       # Number of inference steps\n",
    "    sampling_protocal='protocal_1',     # Sampling protocal ('protocal_1' or 'protocal_2')\n",
    "    config='configs/ar_config.py'     # Path to the config file\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7024cbd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4385952",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805a9c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model download\n",
    "local_path = snapshot_download(\n",
    "        repo_id=\"amd/Instella-T2I\",\n",
    "        local_dir=args.ckpt_path, \n",
    "    )\n",
    "\n",
    "print(\"Model downloaded to:\", local_path)\n",
    "\n",
    "model_config = Config.fromfile(args.config)\n",
    "bae_config = Config.fromfile(model_config.bae_config)\n",
    "bae_ckpt = model_config.bae_ckpt\n",
    "\n",
    "print(f\"BAE checkpoint path: {bae_ckpt}\")\n",
    "print(f\"BAE checkpoint exists: {os.path.exists(bae_ckpt)}\")\n",
    "\n",
    "weight_dtype = torch.bfloat16\n",
    "\n",
    "# ======================================================\n",
    "# Build models\n",
    "# ======================================================\n",
    "print('Build diffusion model and load weight')\n",
    "olmo_path = 'amd/AMD-OLMo-1B'\n",
    "llm = AutoModelForCausalLM.from_pretrained(olmo_path, attn_implementation=\"flash_attention_2\", torch_dtype=weight_dtype).to(\"cuda\") # remove .to(\"cuda\") to load on cpu\n",
    "tokenizer = AutoTokenizer.from_pretrained(olmo_path, model_max_length=128, padding_side='left')\n",
    "\n",
    "model = Instella_AR_Model(\n",
    "                            in_channels = bae_config.codebook_size,\n",
    "                            num_layers = llm.config.num_hidden_layers,\n",
    "                            attention_head_dim = model_config.get('attention_head_dim', 128),\n",
    "                            num_attention_heads = model_config.get('num_attention_heads', 16),\n",
    "                            num_img_tkns = model_config.num_tkns,\n",
    "                            text_cond_dim = llm.config.hidden_size,\n",
    "                            )\n",
    "\n",
    "model.eval()\n",
    "\n",
    "ckpt = torch.load(f'{args.ckpt_path}/ar.pt', map_location='cpu')['module']\n",
    "model.load_state_dict(ckpt)\n",
    "\n",
    "bae = BAE_Model(bae_config)\n",
    "\n",
    "print('Loading BAE model weights')\n",
    "# Fixed: Removed device='cpu' parameter that was causing \"No such device\" error\n",
    "bae_state_dict = safe_load_file(bae_ckpt)\n",
    "bae.load_state_dict(bae_state_dict, strict=True)\n",
    "del bae_state_dict\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "bae.to('cuda', dtype=weight_dtype)\n",
    "bae.eval()\n",
    "if model_config.get('bae_scale', None) is not None:\n",
    "    bae.set_scale(model_config.bae_scale)\n",
    "\n",
    "bae.requires_grad_(False)\n",
    "\n",
    "model = model.to('cuda', dtype=weight_dtype)\n",
    "\n",
    "num_sampling_steps = args.num_steps\n",
    "img_size = args.image_size\n",
    "\n",
    "guidance_scale = args.cfg_scale\n",
    "temp = args.temp\n",
    "\n",
    "binary_ar = BinaryAR(model_config.num_tkns)\n",
    "\n",
    "os.makedirs('results', exist_ok=True)\n",
    "\n",
    "print(\"✓ All models loaded and ready for inference!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb604ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seeds for reproducible results\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def set_seeds(seed=42):\n",
    "    \"\"\"Set all random seeds for reproducibility\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # For multi-GPU setups\n",
    "    \n",
    "    # Make CuDNN deterministic (may impact performance)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "    # Set Python hash seed for complete reproducibility\n",
    "    import os\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    \n",
    "    print(f\"All seeds set to {seed} for reproducible results\")\n",
    "\n",
    "# Set the seed\n",
    "SEED = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2842463",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch generation - generate multiple images from a list of prompts\n",
    "set_seeds(1)\n",
    "delta = 0\n",
    "text = \"A dog\"                                                                                                                                                              \n",
    "with torch.no_grad():\n",
    "    ts = time.time()\n",
    "    z = binary_ar.sample(model, tokenizer, llm, [text], guidance_scale=guidance_scale, temp=temp, delta=delta)\n",
    "    z = z.to(weight_dtype)\n",
    "    \n",
    "    samples = bae.decode(z, img_size//16, img_size//16)\n",
    "    te = time.time()\n",
    "\n",
    "    samples = samples[0].float()\n",
    "\n",
    "    samples = torch.clamp(samples, -1.0, 1.0)\n",
    "    samples = (samples + 1) / 2\n",
    "\n",
    "    samples = samples.permute(1, 2, 0).mul_(255).cpu().numpy()\n",
    "    image = Image.fromarray(samples.astype(np.uint8))\n",
    "    name = text.split(' ')[:5]\n",
    "    name = '_'.join(name)\n",
    "    image.save(f'results/{img_size}_{num_sampling_steps}_{guidance_scale}_{temp}_{name}.jpg')\n",
    "    sp = te - ts\n",
    "print(f'Generation finished in {sp:.2f}s')\n",
    "display(image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727774fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(z)  # Print the shape of the generated latent codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0015e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c836af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invert the image processing - reverse the normalization\n",
    "image = image.resize((512,512), Image.LANCZOS)\n",
    "samples = torch.tensor(np.array(image.copy()))\n",
    "\n",
    "# Reverse the operations: convert back from [0,1] to [-1,1] range\n",
    "samples = samples / 255.0  # Convert from [0,255] to [0,1]\n",
    "samples = samples.permute(2, 0, 1)  # Convert from HWC to CHW format\n",
    "samples = samples * 2 - 1  # Convert from [0,1] to [-1,1]\n",
    "samples = torch.clamp(samples, -1.0, 1.0)\n",
    "\n",
    "print(f\"Inverted samples shape: {samples.shape}\")\n",
    "print(f\"Inverted samples range: [{samples.min():.3f}, {samples.max():.3f}]\")\n",
    "\n",
    "# If you want to encode this back through the BAE encoder:\n",
    "samples_batch = samples.unsqueeze(0).to('cuda', dtype=weight_dtype)  # Add batch dimension\n",
    "encoded = bae.encode(samples_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854e8ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits, smth, binary = encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5261d465",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(z.reshape(-1).to(torch.int32).tolist())  # Print the binary code as a flat list\n",
    "print(binary['binary_code'].reshape(-1).to(torch.int32).tolist())  # Print the binary code as a flat list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03af9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the matching ratio between z and binary['binary_code']\n",
    "import torch\n",
    "\n",
    "# Flatten both tensors for comparison\n",
    "z_flat = z.reshape(-1).to(torch.int32)\n",
    "binary_flat = binary['binary_code'].reshape(-1).to(torch.int32)\n",
    "\n",
    "print(f\"z shape: {z.shape}\")\n",
    "print(f\"binary['binary_code'] shape: {binary['binary_code'].shape}\")\n",
    "print(f\"z_flat shape: {z_flat.shape}\")\n",
    "print(f\"binary_flat shape: {binary_flat.shape}\")\n",
    "\n",
    "# Check if they have the same size\n",
    "if z_flat.shape[0] == binary_flat.shape[0]:\n",
    "    # Count matches\n",
    "    matches = (z_flat == binary_flat).sum().item()\n",
    "    total = z_flat.shape[0]\n",
    "    match_ratio = matches / total\n",
    "    \n",
    "    print(f\"\\nMatching comparison:\")\n",
    "    print(f\"Total elements: {total}\")\n",
    "    print(f\"Matching elements: {matches}\")\n",
    "    print(f\"Non-matching elements: {total - matches}\")\n",
    "    print(f\"Matching ratio: {match_ratio:.4f} ({match_ratio*100:.2f}%)\")\n",
    "    \n",
    "    # Show first few elements for inspection\n",
    "    print(f\"\\nFirst 20 elements comparison:\")\n",
    "    print(f\"z:      {z_flat[:20].tolist()}\")\n",
    "    print(f\"binary: {binary_flat[:20].tolist()}\")\n",
    "    print(f\"match:  {(z_flat[:20] == binary_flat[:20]).tolist()}\")\n",
    "    \n",
    "else:\n",
    "    print(f\"Size mismatch! z has {z_flat.shape[0]} elements, binary has {binary_flat.shape[0]} elements\")\n",
    "    \n",
    "    # Try to find if one is a subset of the other\n",
    "    min_size = min(z_flat.shape[0], binary_flat.shape[0])\n",
    "    matches = (z_flat[:min_size] == binary_flat[:min_size]).sum().item()\n",
    "    match_ratio = matches / min_size\n",
    "    \n",
    "    print(f\"Comparing first {min_size} elements:\")\n",
    "    print(f\"Matching elements: {matches}\")\n",
    "    print(f\"Matching ratio: {match_ratio:.4f} ({match_ratio*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41eeea7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3bd479",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
